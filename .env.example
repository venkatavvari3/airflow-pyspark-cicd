# Development environment configuration
ENVIRONMENT=dev
LOG_LEVEL=DEBUG

# Spark Configuration
SPARK_MASTER=local[*]
SPARK_APP_NAME=PySpark-Development
SPARK_SQL_WAREHOUSE_DIR=/tmp/spark-warehouse

# AWS Configuration
AWS_REGION=us-east-1
AWS_S3_BUCKET=my-dev-data-bucket

# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=airflow_dev
DB_USER=airflow
DB_PASSWORD=airflow

# Airflow Configuration
AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost:5432/airflow_dev
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
